{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/gdrive\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hB_me_nSEaZK",
    "outputId": "d7b76a50-12a6-489e-a525-c15a57ca0c79",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:28.500631Z",
     "start_time": "2023-11-08T06:51:28.464211Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the dataset\n",
    "Note: we will need to turn the label values into -1 and 1."
   ],
   "metadata": {
    "id": "auWjo33EGHTW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"/Users/divytripathy/PycharmProjects/Machine Learning/Perceptron/bank-note/train.csv\", names=['variance', 'skewness', 'curtosis', 'entropy', 'label'])\n",
    "print(train.head())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jw3M5MMpEf4H",
    "outputId": "0166664b-7478-4c08-d46f-d9810234323f",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:28.525413Z",
     "start_time": "2023-11-08T06:51:28.470788Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   variance  skewness  curtosis  entropy  label\n",
      "0  3.848100  10.15390  -3.85610 -4.22280      0\n",
      "1  4.004700   0.45937   1.36210  1.61810      0\n",
      "2 -0.048008  -1.60370   8.47560  0.75558      0\n",
      "3 -1.266700   2.81830  -2.42600 -1.88620      1\n",
      "4  2.203400   5.99470   0.53009  0.84998      0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train['label'] = train['label'].apply(lambda x: 1 if x == 1 else -1)\n",
    "print(train.head())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCG7NEKYGRxO",
    "outputId": "b1970432-9d17-4885-a478-e5ed525cd25f",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:28.547801Z",
     "start_time": "2023-11-08T06:51:28.477831Z"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   variance  skewness  curtosis  entropy  label\n",
      "0  3.848100  10.15390  -3.85610 -4.22280     -1\n",
      "1  4.004700   0.45937   1.36210  1.61810     -1\n",
      "2 -0.048008  -1.60370   8.47560  0.75558     -1\n",
      "3 -1.266700   2.81830  -2.42600 -1.88620      1\n",
      "4  2.203400   5.99470   0.53009  0.84998     -1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test = pd.read_csv(\"/Users/divytripathy/PycharmProjects/Machine Learning/Perceptron/bank-note/test.csv\", names=['variance', 'skewness', 'curtosis', 'entropy', 'label'])\n",
    "print(test.head())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZR-WurHZGl5P",
    "outputId": "d5c43d20-883f-420a-b5d0-2fb97e94b152",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:28.582343Z",
     "start_time": "2023-11-08T06:51:28.481142Z"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   variance  skewness  curtosis   entropy  label\n",
      "0   3.83840    6.1851  -2.04390 -0.033204      0\n",
      "1   2.85210    9.1710  -3.64610 -1.204700      0\n",
      "2   5.24180   10.5388  -4.11740 -4.279700      0\n",
      "3  -2.26230   12.1177   0.28846 -7.758100      0\n",
      "4   0.55298   -3.4619   1.70480  1.100800      1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test['label'] = test['label'].apply(lambda x: 1 if x == 1 else -1)\n",
    "print(test.head())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_mPCyA8GuUb",
    "outputId": "1c69e8d9-004f-473c-9667-78702b6ab353",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:28.600382Z",
     "start_time": "2023-11-08T06:51:28.487554Z"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   variance  skewness  curtosis   entropy  label\n",
      "0   3.83840    6.1851  -2.04390 -0.033204     -1\n",
      "1   2.85210    9.1710  -3.64610 -1.204700     -1\n",
      "2   5.24180   10.5388  -4.11740 -4.279700     -1\n",
      "3  -2.26230   12.1177   0.28846 -7.758100     -1\n",
      "4   0.55298   -3.4619   1.70480  1.100800      1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our Class:"
   ],
   "metadata": {
    "id": "aNeKlxeCEW5T"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IA1D9TLD6G2O",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:31.161100Z",
     "start_time": "2023-11-08T06:51:28.494741Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class Perceptron:\n",
    "  def standard_perceptron(self, X: np.ndarray, Y: np.ndarray, rate: int=1, epoch: int=1):\n",
    "    \"\"\"\n",
    "    This only works when the output is binary in the form of -1 or 1.\n",
    "    \"\"\"\n",
    "    weights: np.ndarray = np.zeros(len(X[0]))\n",
    "    copy_X = X[:]\n",
    "    copy_Y = Y[:]\n",
    "    for _ in range(epoch):\n",
    "      copy_X, copy_Y = shuffle(copy_X, copy_Y)\n",
    "      for row, y in zip(copy_X, copy_Y):\n",
    "        y_pred = np.sign(np.dot(weights, row)).astype(np.int64)\n",
    "        if y != y_pred:\n",
    "          weights = weights + rate * (y * row)\n",
    "    return weights\n",
    "\n",
    "  def voted_perceptron(self, X: np.ndarray, Y: np.ndarray, rate: int=1, epoch: int=1):\n",
    "    \"\"\"\n",
    "    This only works when the output is binary in the form of -1 or 1.\n",
    "    returns weights in the form of a list of tuples (weights_i, c_i)\n",
    "    \"\"\"\n",
    "    weights_array: list[tuple] = []\n",
    "    weights: np.ndarray = np.zeros(len(X[0]))\n",
    "    c: int = 0\n",
    "\n",
    "    copy_X = X[:]\n",
    "    copy_Y = Y[:]\n",
    "\n",
    "    for _ in range(epoch):\n",
    "      copy_X, copy_Y = shuffle(copy_X, copy_Y)\n",
    "      for row, y in zip(copy_X, copy_Y):\n",
    "        y_pred = np.sign(np.dot(weights, row)).astype(np.int64)\n",
    "        if y != y_pred:\n",
    "          weights_array.append((weights, c))\n",
    "          weights = weights + rate * (y * row)\n",
    "          c = 1\n",
    "        else:\n",
    "          c += 1\n",
    "    return weights_array\n",
    "\n",
    "  def average_perceptron(self, X: np.ndarray, Y: np.ndarray, rate: int=1, epoch: int=1):\n",
    "    \"\"\"\n",
    "    This only works when the output is binary in the form of -1 or 1.\n",
    "    \"\"\"\n",
    "    weights: np.ndarray = np.zeros(len(X[0]))\n",
    "    a: np.ndarray = np.zeros(len(X[0]))\n",
    "    copy_X = X[:]\n",
    "    copy_Y = Y[:]\n",
    "    for _ in range(epoch):\n",
    "      copy_X, copy_Y = shuffle(copy_X, copy_Y)\n",
    "      for row, y in zip(copy_X, copy_Y):\n",
    "        y_pred = np.sign(np.dot(weights, row)).astype(np.int64)\n",
    "        if y != y_pred:\n",
    "          weights = weights + rate * (y * row)\n",
    "        a += weights\n",
    "    return a\n",
    "\n",
    "  @staticmethod\n",
    "  def voted_perceptron_predict(datapoint: np.ndarray, weights: list):\n",
    "    predictions: float = 0\n",
    "    for i in range(len(weights)):\n",
    "      predictions += np.dot(weights[i][0], datapoint) * weights[i][1]\n",
    "    return np.sign(predictions).astype(np.int32)\n",
    "\n",
    "  @staticmethod\n",
    "  def bias_trick(X: np.ndarray):\n",
    "    \"\"\"\n",
    "    Used to add 1 to the input array\n",
    "    \"\"\"\n",
    "    output: list[np.ndarray] = []\n",
    "    for i in range(len(X)):\n",
    "      output.append(np.append(X[i], 1))\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quick way to check for if bias_trick works."
   ],
   "metadata": {
    "id": "s5SAOD6FD0fj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "array_ex: np.ndarray = np.array([np.array([1, 3, 3]), np.array([2, 3, 3]), np.array([3, 3, 4]), np.array([4, 3, 1])])\n",
    "print(Perceptron.bias_trick(array_ex))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9LjyXXYEBZ_z",
    "outputId": "54e2482f-c1aa-4f3b-8ece-c6a29f1b2f59",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:31.162821Z",
     "start_time": "2023-11-08T06:51:31.161466Z"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 3 1]\n",
      " [2 3 3 1]\n",
      " [3 3 4 1]\n",
      " [4 3 1 1]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will look at the accuracy of the standard perceptron."
   ],
   "metadata": {
    "id": "9Un1jDMhAjUj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(Perceptron().standard_perceptron(X = Perceptron.bias_trick(train.drop('label', axis=1).values), Y = train['label'].values, epoch=10))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMOEsqXpAI_v",
    "outputId": "96be59d4-953d-4548-ba21-4f30b2e11e1e",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:31.206563Z",
     "start_time": "2023-11-08T06:51:31.164926Z"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-63.17745  -40.17069  -48.991205  -7.601841  52.      ]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets make test predictions."
   ],
   "metadata": {
    "id": "sqFJpkbMNpt_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def accuracy_standard_perceptron(y_test: np.ndarray, x_test: np.ndarray, weights: np.ndarray):\n",
    "  num_observations: int = len(y_test)\n",
    "  correct: int = 0\n",
    "  for i in range(num_observations):\n",
    "    prediction = np.sign(np.dot(weights, x_test[i]))\n",
    "    if prediction == y_test[i]:\n",
    "      correct += 1\n",
    "  return correct / num_observations"
   ],
   "metadata": {
    "id": "Fvi8jdm5Ntje",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:31.207137Z",
     "start_time": "2023-11-08T06:51:31.186434Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "weights = Perceptron().standard_perceptron(X = Perceptron.bias_trick(train.drop('label', axis=1).values), Y = train['label'].values, epoch=10)\n",
    "print(\"standard weights: \", weights)\n",
    "print(\"train accuracy: \", accuracy_standard_perceptron(train['label'].values, Perceptron.bias_trick(train.drop('label', axis=1).values), weights))\n",
    "print(\"test accuracy: \", accuracy_standard_perceptron(test['label'].values, Perceptron.bias_trick(test.drop('label', axis=1).values), weights))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LA9mVM7rQcbf",
    "outputId": "17c070eb-fbd6-4e69-b9aa-d746ea796c80",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:31.220247Z",
     "start_time": "2023-11-08T06:51:31.193393Z"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard weights:  [-62.460361 -43.256255 -34.567106 -13.640989  55.      ]\n",
      "train accuracy:  0.9724770642201835\n",
      "test accuracy:  0.97\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quick check of if everything is as expected."
   ],
   "metadata": {
    "id": "Ct6FuuU_saL8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "weights = Perceptron().voted_perceptron(X = Perceptron.bias_trick(train.drop('label', axis=1).values), Y = train['label'].values, epoch=10)\n",
    "print(len(weights))"
   ],
   "metadata": {
    "id": "lSQ-zCOgQjjp",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "74181a70-2fda-4338-8f8e-8a67c639e7b8",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:31.255203Z",
     "start_time": "2023-11-08T06:51:31.223323Z"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets test predictions."
   ],
   "metadata": {
    "id": "2ryw75HUseZh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "prediction = Perceptron.voted_perceptron_predict(Perceptron.bias_trick(train.drop('label', axis=1).values)[0], weights)\n",
    "print(prediction, train['label'].values[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OS3GKPEvshD5",
    "outputId": "5dcb8d06-021c-4d25-9879-ee80ceb8dc7b",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:31.255423Z",
     "start_time": "2023-11-08T06:51:31.248878Z"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 -1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets test accuracy."
   ],
   "metadata": {
    "id": "N_pV-QHAuBWO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def accuracy_voted_perceptron(y_test: np.ndarray, x_test: np.ndarray, weights: list[tuple]):\n",
    "  num_observations: int = len(y_test)\n",
    "  correct: int = 0\n",
    "  for i in range(num_observations):\n",
    "    prediction = Perceptron.voted_perceptron_predict(x_test[i], weights)\n",
    "    if prediction == y_test[i]:\n",
    "      correct += 1\n",
    "  return correct / num_observations"
   ],
   "metadata": {
    "id": "aXrQjVsltRsf",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:31.258152Z",
     "start_time": "2023-11-08T06:51:31.254725Z"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We need to print the count of the weights along with the weights for the voted perceptron."
   ],
   "metadata": {
    "id": "XyoQHMoohVau"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "weights = Perceptron().voted_perceptron(X = Perceptron.bias_trick(train.drop('label', axis=1).values), Y = train['label'].values, epoch=10)\n",
    "print(\"train accuracy: \", accuracy_voted_perceptron(train['label'].values, Perceptron.bias_trick(train.drop('label', axis=1).values), weights))\n",
    "print(\"test accuracy: \", accuracy_voted_perceptron(test['label'].values, Perceptron.bias_trick(test.drop('label', axis=1).values), weights))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcUXleOctxFV",
    "outputId": "e87949a1-78b1-4b1e-8484-2038e414d178",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:31.481592Z",
     "start_time": "2023-11-08T06:51:31.259949Z"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.9873853211009175\n",
      "test accuracy:  0.986\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for weight, count in weights:\n",
    "  print(count, weight)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mk2tctvjh5KJ",
    "outputId": "68b74236-791f-4478-91b5-ce226c8c4731",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:31.483510Z",
     "start_time": "2023-11-08T06:51:31.466149Z"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0. 0. 0. 0. 0.]\n",
      "1 [-1.3995  -1.9162   2.5154   0.59912  1.     ]\n",
      "5 [-3.3335     -1.91619072 -2.3006      0.93879     0.        ]\n",
      "3 [-5.3401     -8.63519072  6.7156      1.038775    1.        ]\n",
      "17 [-7.5017     -1.75479072 -1.4361      1.119823    0.        ]\n",
      "6 [-7.78866     1.42360928 -5.0128     -2.069777    1.        ]\n",
      "13 [-9.20606    -0.82989072 -3.4948     -1.449967    2.        ]\n",
      "1 [ -6.75876    -13.45459072  -4.23053      6.211233     1.        ]\n",
      "2 [ -7.53871    -10.22239072  -7.51253      3.110833     2.        ]\n",
      "15 [-11.16141     -6.22659072  -7.87098     -0.793867     3.        ]\n",
      "2 [-14.43061    -18.96719072   7.68632     -0.935687     4.        ]\n",
      "9 [-16.87921    -12.64969072  -0.27688     -1.141707     3.        ]\n",
      "3 [-18.32711     -7.77029072  -8.61968      0.966893     2.        ]\n",
      "5 [-17.42304     -4.39949072 -13.11838     -2.729607     3.        ]\n",
      "3 [-14.77514    -14.53689072 -11.78738      2.741093     2.        ]\n",
      "2 [-14.709011   -12.04549072 -14.72748      2.119533     3.        ]\n",
      "7 [-14.678792   -13.09669072 -13.32508      2.893223     4.        ]\n",
      "1 [-21.715192    -3.80359072 -13.15914     -1.646377     5.        ]\n",
      "17 [-20.415192   -14.07139072 -10.20614      4.217423     4.        ]\n",
      "21 [-20.486695   -10.33019072 -14.74764     -0.035177     5.        ]\n",
      "2 [-24.182795   -24.00809072   2.83186     -2.653277     6.        ]\n",
      "12 [-26.139995   -18.89279072  -5.78084     -1.223577     5.        ]\n",
      "38 [-24.931995   -14.81839072 -10.54434     -3.836477     6.        ]\n",
      "48 [-22.900995   -12.96639072 -13.55644     -3.833474     7.        ]\n",
      "19 [-21.310595   -10.75429072 -16.67474     -3.950724     8.        ]\n",
      "8 [-19.292895    -8.95609072 -19.63284     -3.740824     9.        ]\n",
      "10 [-21.830195   -15.91509072 -10.82744     -2.211924    10.        ]\n",
      "12 [-21.714275   -12.69319072 -14.25764     -5.057624    11.        ]\n",
      "1 [-19.322575    -8.13669072 -19.24644     -7.956324    12.        ]\n",
      "5 [-22.923775   -14.67559072  -8.72304     -8.445994    13.        ]\n",
      "3 [-21.190675   -10.72119072 -13.46424    -10.947694    14.        ]\n",
      "2 [-21.519915    -6.26599072 -18.03604     -9.958894    13.        ]\n",
      "3 [-22.294525    -8.14279072 -15.63374     -8.826994    14.        ]\n",
      "23 [-25.682925   -16.35779072  -5.30224     -7.845124    15.        ]\n",
      "29 [-27.262825   -11.65019072 -13.22084     -6.296424    14.        ]\n",
      "33 [-25.812725    -8.04349072 -17.27654     -7.893024    15.        ]\n",
      "25 [-26.533405   -14.80179072 -11.43574     -7.269334    16.        ]\n",
      "183 [-25.521705   -13.89959072 -13.78634     -6.842194    17.        ]\n",
      "6 [-24.014005   -11.93999072 -16.84474     -6.964624    18.        ]\n",
      "2 [-27.156305   -24.97649072  -1.16744     -7.626274    19.        ]\n",
      "15 [-29.802605   -20.16129072  -7.52234     -7.629277    18.        ]\n",
      "6 [-29.061935   -18.43139072 -10.71864     -7.774977    19.        ]\n",
      "55 [-28.417215   -13.82519072 -19.06564     -5.065077    18.        ]\n",
      "8 [-25.769315   -23.96259072 -17.73464      0.405623    17.        ]\n",
      "16 [-24.188315   -23.09350072 -20.04844      1.229743    18.        ]\n",
      "15 [-24.707815   -19.83020072 -23.13794      2.214643    17.        ]\n",
      "5 [-28.299415   -26.05870072 -12.89904      1.060343    18.        ]\n",
      "67 [-28.030645   -21.07170072 -18.04984     -5.330957    19.        ]\n",
      "8 [-26.810845   -18.97350072 -21.24524     -5.202527    20.        ]\n",
      "20 [-24.616545   -14.42320072 -26.22124     -7.927927    21.        ]\n",
      "22 [-23.316545   -24.69100072 -23.26824     -2.064127    20.        ]\n",
      "2 [-24.142555   -21.72990072 -24.55464     -3.528827    21.        ]\n",
      "51 [-24.662025   -18.46660072 -27.64414     -2.543907    20.        ]\n",
      "46 [-26.344025   -25.27870072 -20.50434     -1.211607    21.        ]\n",
      "88 [-33.303925   -16.28560072 -20.28614     -5.783607    22.        ]\n",
      "14 [-32.517025   -25.85190072 -16.49944      1.719793    21.        ]\n",
      "11 [-31.549945   -22.00930072 -21.43084     -2.412507    22.        ]\n",
      "24 [-32.069445   -18.74600072 -24.52034     -1.427607    21.        ]\n",
      "41 [-30.038445   -16.89400072 -27.53244     -1.424604    22.        ]\n",
      "96 [-33.643745   -22.86800072 -17.44084     -2.253064    23.        ]\n",
      "22 [-33.972945   -18.41280072 -22.01264     -1.264264    22.        ]\n",
      "3 [-31.778645   -13.86250072 -26.98864     -3.989664    23.        ]\n",
      "1 [-34.070445   -21.11950072 -19.02894     -3.068564    24.        ]\n",
      "8 [-32.813245   -16.24640072 -24.31504     -8.942664    25.        ]\n",
      "25 [-31.513245   -26.51420072 -21.36204     -3.078864    24.        ]\n",
      "21 [-35.506645   -20.68090072 -20.81481     -8.016764    25.        ]\n",
      "10 [-33.114945   -16.12440072 -25.80361    -10.915464    26.        ]\n",
      "49 [-31.814945   -26.39220072 -22.85061     -5.051664    25.        ]\n",
      "13 [-30.081845   -22.43780072 -27.59181     -7.553364    26.        ]\n",
      "4 [-30.601345   -19.17450072 -30.68131     -6.568464    25.        ]\n",
      "80 [-32.863045   -23.91730072 -24.33241     -6.456844    26.        ]\n",
      "7 [-33.382545   -20.65400072 -27.42191     -5.471944    25.        ]\n",
      "25 [-37.078645   -34.33190072  -9.84241     -8.090044    26.        ]\n",
      "2 [-36.337975   -32.60200072 -13.03871     -8.235744    27.        ]\n",
      "38 [-36.27545    -29.67190072 -16.58541    -10.909444    28.        ]\n",
      "22 [-37.63925    -24.89600072 -25.00361     -9.025844    27.        ]\n",
      "2 [-36.18915    -21.28930072 -29.05931    -10.622444    28.        ]\n",
      "51 [-40.56645    -26.80600072 -18.12031    -11.030644    29.        ]\n",
      "42 [-40.89569    -22.35080072 -22.69211    -10.041844    28.        ]\n",
      "3 [-41.41516    -19.08750072 -25.78161     -9.056924    27.        ]\n",
      "41 [-38.76726    -29.22490072 -24.45061     -3.586224    26.        ]\n",
      "100 [-37.70356    -25.52920072 -28.61001     -5.524124    27.        ]\n",
      "3 [-35.68586    -23.73100072 -31.56811     -5.314224    28.        ]\n",
      "4 [-39.70316    -32.04330072 -19.11341     -6.751724    29.        ]\n",
      "98 [-38.73608    -28.20070072 -24.04481    -10.884024    30.        ]\n",
      "53 [-37.51628    -26.10250072 -27.24021    -10.755594    31.        ]\n",
      "15 [-35.32198    -21.55220072 -32.21621    -13.480994    32.        ]\n",
      "139 [-35.04398    -29.74030072 -29.08241    -10.953394    31.        ]\n",
      "4 [-35.56345    -26.47700072 -32.17191     -9.968474    30.        ]\n",
      "18 [-34.77655    -36.04330072 -28.38521     -2.465074    29.        ]\n",
      "18 [-34.50324    -31.16600072 -33.30461     -8.284874    30.        ]\n",
      "3 [-37.58984    -37.80220072 -22.76411     -9.176694    31.        ]\n",
      "36 [-36.90804    -32.95180072 -27.97741    -15.280994    32.        ]\n",
      "109 [-34.87704    -31.09980072 -30.98951    -15.277991    33.        ]\n",
      "23 [-35.20624    -26.64460072 -35.56131    -14.289191    32.        ]\n",
      "2 [-39.02654    -39.69970072 -18.60301    -16.594391    33.        ]\n",
      "15 [-36.63484    -35.14320072 -23.59181    -19.493091    34.        ]\n",
      "96 [-35.31654    -33.24150072 -26.90291    -19.42802     35.        ]\n",
      "12 [-35.83604    -29.97820072 -29.99241    -18.44312     34.        ]\n",
      "2 [-35.67496    -23.51580072 -38.34971    -16.92152     33.        ]\n",
      "11 [-39.27616    -30.05470072 -27.82631    -17.41119     34.        ]\n",
      "143 [-39.79566    -26.79140072 -30.91581    -16.42629     33.        ]\n",
      "1 [-39.00876    -36.35770072 -27.12911     -8.92289     32.        ]\n",
      "21 [-39.338      -31.90250072 -31.70091     -7.93409     31.        ]\n",
      "7 [-39.8575     -28.63920072 -34.79041     -6.94919     30.        ]\n",
      "28 [-44.534      -34.30280072 -23.82141     -7.28368     31.        ]\n",
      "29 [-42.9436     -32.09070072 -26.93971     -7.40093     32.        ]\n",
      "165 [-43.4631     -28.82740072 -30.02921     -6.41603     31.        ]\n",
      "18 [-41.2688     -24.27710072 -35.00521     -9.14143     32.        ]\n",
      "1 [-45.0891     -37.33220072 -18.04691    -11.44663     33.        ]\n",
      "20 [-44.4073     -32.48180072 -23.26021    -17.55093     34.        ]\n",
      "54 [-42.3763     -30.62980072 -26.27231    -17.547927    35.        ]\n",
      "9 [-42.70554    -26.17460072 -30.84411    -16.559127    34.        ]\n",
      "51 [-41.40554    -36.44240072 -27.89111    -10.695327    33.        ]\n",
      "34 [-39.72564    -32.23560072 -32.43091    -13.088427    34.        ]\n",
      "12 [-40.24514    -28.97230072 -35.52041    -12.103527    33.        ]\n",
      "7 [-42.25174    -35.69130072 -26.50421    -12.003542    34.        ]\n",
      "179 [-39.86004    -31.13480072 -31.49301    -14.902242    35.        ]\n",
      "23 [-40.37951    -27.87150072 -34.58251    -13.917322    34.        ]\n",
      "19 [-41.03718    -30.67330072 -30.87101    -12.919932    35.        ]\n",
      "74 [-41.55668    -27.41000072 -33.96051    -11.935032    34.        ]\n",
      "3 [-44.64328    -34.04620072 -23.42001    -12.826852    35.        ]\n",
      "15 [-45.57298    -30.24910072 -28.06291    -12.531152    34.        ]\n",
      "59 [-45.90218    -25.79390072 -32.63471    -11.542352    33.        ]\n",
      "2 [-43.88448    -23.99570072 -35.59281    -11.332452    34.        ]\n",
      "17 [-48.56098    -29.65930072 -24.62381    -11.666942    35.        ]\n",
      "79 [-47.07138    -26.23050072 -28.65471    -13.092842    36.        ]\n",
      "24 [-47.59088    -22.96720072 -31.74421    -12.107942    35.        ]\n",
      "22 [-46.80398    -32.53350072 -27.95751     -4.604542    34.        ]\n",
      "28 [-45.74028    -28.83780072 -32.11691     -6.542442    35.        ]\n",
      "5 [-43.34858    -24.28130072 -37.10571     -9.441142    36.        ]\n",
      "2 [-44.91068    -26.49340072 -32.84661     -9.161422    37.        ]\n",
      "2 [-45.43015    -23.23010072 -35.93611     -8.176502    36.        ]\n",
      "1 [-49.91625    -36.51900072 -18.62741    -11.395902    37.        ]\n",
      "8 [-49.23445    -31.66860072 -23.84071    -17.500202    38.        ]\n",
      "63 [-47.88265    -30.60910072 -26.18441    -17.100222    39.        ]\n",
      "43 [-45.86495    -28.81090072 -29.14251    -16.890322    40.        ]\n",
      "25 [-43.21705    -38.94830072 -27.81151    -11.419622    39.        ]\n",
      "44 [-41.72745    -35.51950072 -31.84241    -12.845522    40.        ]\n",
      "55 [-39.53315    -30.96920072 -36.81841    -15.570922    41.        ]\n",
      "21 [-43.91045    -36.48590072 -25.87941    -15.979122    42.        ]\n",
      "14 [-42.69065    -34.38770072 -29.07481    -15.850692    43.        ]\n",
      "29 [-41.10965    -33.51861072 -31.38861    -15.026572    44.        ]\n",
      "26 [-39.07865    -31.66661072 -34.40071    -15.023569    45.        ]\n",
      "3 [-39.40789    -27.21141072 -38.97251    -14.034769    44.        ]\n",
      "34 [-42.63839    -34.42491072 -27.32921    -14.980899    45.        ]\n",
      "6 [-40.85089    -29.64491072 -32.46541    -18.217099    46.        ]\n",
      "11 [-40.68981    -23.18251072 -40.82271    -16.695499    45.        ]\n",
      "9 [-41.34748    -25.98431072 -37.11121    -15.698109    46.        ]\n",
      "12 [-41.86698    -22.72101072 -40.20071    -14.713209    45.        ]\n",
      "45 [-43.66458    -29.48961072 -33.52541    -13.814089    46.        ]\n",
      "10 [-42.87768    -39.05591072 -29.73871     -6.310689    45.        ]\n",
      "79 [-49.21408    -29.77111072 -29.724435   -13.095089    46.        ]\n",
      "276 [-49.73358    -26.50781072 -32.813935   -12.110189    45.        ]\n",
      "16 [-50.25308    -23.24451072 -35.903435   -11.125289    44.        ]\n",
      "154 [-49.97508    -31.43261072 -32.769635    -8.597689    43.        ]\n",
      "186 [-50.49458    -28.16931072 -35.859135    -7.612789    42.        ]\n",
      "3 [-48.47688    -26.37111072 -38.817235    -7.402889    43.        ]\n",
      "4 [-52.96298    -39.66001072 -21.508535   -10.622289    44.        ]\n",
      "17 [-51.74318    -37.56181072 -24.703935   -10.493859    45.        ]\n",
      "51 [-50.67948    -33.86611072 -28.863335   -12.431759    46.        ]\n",
      "1 [-49.22938    -30.25941072 -32.919035   -14.028359    47.        ]\n",
      "19 [-49.74885    -26.99611072 -36.008535   -13.043439    46.        ]\n",
      "34 [-50.26835    -23.73281072 -39.098035   -12.058539    45.        ]\n",
      "3 [-53.10745    -30.36281072 -28.613135   -12.479669    46.        ]\n",
      "48 [-52.46273    -25.75661072 -36.960135    -9.769769    45.        ]\n",
      "19 [-55.73193    -38.49721072 -21.402835    -9.911589    46.        ]\n",
      "1 [-53.70093    -36.64521072 -24.414935    -9.908586    47.        ]\n",
      "29 [-52.02103    -32.43841072 -28.954735   -12.301686    48.        ]\n",
      "15 [-51.85995    -25.97601072 -37.312035   -10.780086    47.        ]\n",
      "48 [-50.55995    -36.24381072 -34.359035    -4.916286    46.        ]\n",
      "67 [-50.88915    -31.78861072 -38.930835    -3.927486    45.        ]\n",
      "9 [-54.58525    -45.46651072 -21.351335    -6.545586    46.        ]\n",
      "17 [-55.29095    -39.96841072 -29.688135    -3.674086    45.        ]\n",
      "39 [-54.32387    -36.12581072 -34.619535    -7.806386    46.        ]\n",
      "68 [-52.53637    -31.34581072 -39.755735   -11.042586    47.        ]\n",
      "6 [-56.28667    -44.80441072 -22.162535   -13.819686    48.        ]\n",
      "12 [-54.26897    -43.00621072 -25.120635   -13.609786    49.        ]\n",
      "46 [-56.36117    -36.19621072 -33.584235   -13.007626    48.        ]\n",
      "30 [-54.91107    -32.58951072 -37.639935   -14.604226    49.        ]\n",
      "83 [-55.43057    -29.32621072 -40.729435   -13.619326    48.        ]\n",
      "89 [-52.78267    -39.46361072 -39.398435    -8.148626    47.        ]\n",
      "10 [-53.11191    -35.00841072 -43.970235    -7.159826    46.        ]\n",
      "2 [-56.19851    -41.64461072 -33.429735    -8.051646    47.        ]\n",
      "30 [-56.71801    -38.38131072 -36.519235    -7.066746    46.        ]\n",
      "41 [-57.04721    -33.92611072 -41.091035    -6.077946    45.        ]\n",
      "68 [-54.65551    -29.36961072 -46.079835    -8.976646    46.        ]\n",
      "84 [-52.79711    -37.25561072 -44.415535    -7.138246    45.        ]\n",
      "2 [-56.49321    -50.93351072 -26.836035    -9.756346    46.        ]\n",
      "26 [-55.8859     -46.97911072 -31.608035   -14.241646    47.        ]\n",
      "5 [-54.8222     -43.28341072 -35.767435   -16.179546    48.        ]\n",
      "56 [-55.3417     -40.02011072 -38.856935   -15.194646    47.        ]\n",
      "2 [-55.18062    -33.55771072 -47.214235   -13.673046    46.        ]\n",
      "24 [-57.18722    -40.27671072 -38.198035   -13.573061    47.        ]\n",
      "82 [-54.99292    -35.72641072 -43.174035   -16.298461    48.        ]\n",
      "21 [-55.51239    -32.46311072 -46.263535   -15.313541    47.        ]\n",
      "174 [-60.18889    -38.12671072 -35.294535   -15.648031    48.        ]\n",
      "1 [-58.60789    -37.25762072 -37.608335   -14.823911    49.        ]\n",
      "16 [-57.01749    -35.04552072 -40.726635   -14.941161    50.        ]\n",
      "53 [-54.99979    -33.24732072 -43.684735   -14.731261    51.        ]\n",
      "88 [-58.82009    -46.30242072 -26.726435   -17.036461    52.        ]\n",
      "2 [-58.17537    -41.69622072 -35.073435   -14.326561    51.        ]\n",
      "86 [-56.72527    -38.08952072 -39.129135   -15.923161    52.        ]\n",
      "329 [-57.24474    -34.82622072 -42.218635   -14.938241    51.        ]\n",
      "81 [-57.76424    -31.56292072 -45.308135   -13.953341    50.        ]\n",
      "17 [-59.77084    -38.28192072 -36.291935   -13.853356    51.        ]\n",
      "22 [-60.29034    -35.01862072 -39.381435   -12.868456    50.        ]\n",
      "31 [-60.80984    -31.75532072 -42.470935   -11.883556    49.        ]\n",
      "23 [-64.50594    -45.43322072 -24.891435   -14.501656    50.        ]\n",
      "15 [-64.34486    -38.97082072 -33.248735   -12.980056    49.        ]\n",
      "23 [-61.95316    -34.41432072 -38.237535   -15.878756    50.        ]\n",
      "5 [-59.92216    -32.56232072 -41.249635   -15.875753    51.        ]\n",
      "61 [-57.27426    -42.69972072 -39.918635   -10.405053    50.        ]\n",
      "73 [-55.07996    -38.14942072 -44.894635   -13.130453    51.        ]\n",
      "22 [-55.59946    -34.88612072 -47.984135   -12.145553    50.        ]\n",
      "23 [-58.86866    -47.62672072 -32.426835   -12.287373    51.        ]\n",
      "31 [-57.61146    -42.75362072 -37.712935   -18.161473    52.        ]\n",
      "85 [-57.45038    -36.29122072 -46.070235   -16.639873    51.        ]\n",
      "37 [-57.96985    -33.02792072 -49.159735   -15.654953    50.        ]\n",
      "108 [-57.18295    -42.59422072 -45.373035    -8.151553    49.        ]\n",
      "4 [-54.79125    -38.03772072 -50.361835   -11.050253    50.        ]\n",
      "113 [-56.32345    -43.13432072 -43.683935   -10.875273    51.        ]\n",
      "126 [-54.30575    -41.33612072 -46.642035   -10.665373    52.        ]\n",
      "33 [-57.14485    -47.96612072 -36.157135   -11.086503    53.        ]\n",
      "16 [-57.47405    -43.51092072 -40.728935   -10.097703    52.        ]\n",
      "7 [-55.79415    -39.30412072 -45.268735   -12.490803    53.        ]\n",
      "26 [-56.31365    -36.04082072 -48.358235   -11.505903    52.        ]\n",
      "5 [-60.69095    -41.55752072 -37.419235   -11.914103    53.        ]\n",
      "36 [-59.20135    -38.12872072 -41.450135   -13.340003    54.        ]\n",
      "49 [-59.72085    -34.86542072 -44.539635   -12.355103    53.        ]\n",
      "18 [-63.41695    -48.54332072 -26.960135   -14.973203    54.        ]\n",
      "12 [-62.06515    -47.48382072 -29.303835   -14.573223    55.        ]\n",
      "163 [-60.33205    -43.52942072 -34.045035   -17.074923    56.        ]\n",
      "27 [-58.75105    -42.66033072 -36.358835   -16.250803    57.        ]\n",
      "5 [-57.26145    -39.23153072 -40.389735   -17.676703    58.        ]\n",
      "139 [-57.78095    -35.96823072 -43.479235   -16.691803    57.        ]\n",
      "70 [-58.11019    -31.51303072 -48.051035   -15.703003    56.        ]\n",
      "17 [-61.34069    -38.72653072 -36.407735   -16.649133    57.        ]\n",
      "76 [-61.86019    -35.46323072 -39.497235   -15.664233    56.        ]\n",
      "31 [-59.46849    -30.90673072 -44.486035   -18.562933    57.        ]\n",
      "12 [-63.28879    -43.96183072 -27.527735   -20.868133    58.        ]\n",
      "7 [-64.21849    -40.16473072 -32.170635   -20.572433    57.        ]\n",
      "19 [-62.43099    -35.38473072 -37.306835   -23.808633    58.        ]\n",
      "25 [-62.95046    -32.12143072 -40.396335   -22.823713    57.        ]\n",
      "4 [-60.91946    -30.26943072 -43.408435   -22.82071     58.        ]\n",
      "29 [-64.06176    -43.30593072 -27.731135   -23.48236     59.        ]\n",
      "29 [-62.99806    -39.61023072 -31.890535   -25.42026     60.        ]\n",
      "38 [-63.51756    -36.34693072 -34.980035   -24.43536     59.        ]\n",
      "49 [-62.87284    -31.74073072 -43.327035   -21.72546     58.        ]\n",
      "39 [-63.12319    -41.06693072 -39.639735   -15.47116     57.        ]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets check the average perceptron accuracy."
   ],
   "metadata": {
    "id": "nc7JLE0xx6y_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def accuracy_average_perceptron(y_test: np.ndarray, x_test: np.ndarray, weights: np.ndarray):\n",
    "  num_observations: int = len(y_test)\n",
    "  correct: int = 0\n",
    "  for i in range(num_observations):\n",
    "    prediction = np.sign(np.dot(weights, x_test[i]))\n",
    "    if prediction == y_test[i]:\n",
    "      correct += 1\n",
    "  return correct / num_observations"
   ],
   "metadata": {
    "id": "A1yocdcWyEWG",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:31.483595Z",
     "start_time": "2023-11-08T06:51:31.479262Z"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "weights = Perceptron().average_perceptron(X = Perceptron.bias_trick(train.drop('label', axis=1).values), Y = train['label'].values, epoch=10)\n",
    "print(\"average perceptron weights: \", weights)\n",
    "print(\"train accuracy: \", accuracy_average_perceptron(train['label'].values, Perceptron.bias_trick(train.drop('label', axis=1).values), weights))\n",
    "print(\"test accuracy: \", accuracy_average_perceptron(test['label'].values, Perceptron.bias_trick(test.drop('label', axis=1).values), weights))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdnjrkr5yI1o",
    "outputId": "2a4dbd06-8cd7-4691-ed17-6babf6378c0c",
    "ExecuteTime": {
     "end_time": "2023-11-08T06:51:31.534211Z",
     "start_time": "2023-11-08T06:51:31.482798Z"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average perceptron weights:  [-385681.46765    -253228.58670999 -252842.27964101  -77965.229805\n",
      "  349363.        ]\n",
      "train accuracy:  0.9850917431192661\n",
      "test accuracy:  0.986\n"
     ]
    }
   ]
  }
 ]
}
